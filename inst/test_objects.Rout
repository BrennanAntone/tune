
R version 4.3.2 (2023-10-31) -- "Eye Holes"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5          ✔ recipes      1.0.10    
✔ dials        1.2.1          ✔ rsample      1.2.0     
✔ dplyr        1.1.4          ✔ tibble       3.2.1     
✔ ggplot2      3.5.0          ✔ tidyr        1.3.1     
✔ infer        1.0.5          ✔ tune         1.2.0     
✔ modeldata    1.3.0          ✔ workflows    1.1.4     
✔ parsnip      1.2.0          ✔ workflowsets 1.0.1.9001
✔ purrr        1.0.2          ✔ yardstick    1.3.0     
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use suppressPackageStartupMessages() to eliminate package startup messages
> library(scales)
> library(censored)
Loading required package: survival
> library(sessioninfo)
> library(testthat)

Attaching package: ‘testthat’

The following object is masked from ‘package:tidyr’:

    matches

The following object is masked from ‘package:rsample’:

    matches

The following object is masked from ‘package:purrr’:

    is_null

The following object is masked from ‘package:dplyr’:

    matches

> # also will require prodlim, mboost, kknn, and kernlab
> 
> # ------------------------------------------------------------------------------
> # "mt_*" test objects used in test-predictions.R, test-extract.R, and test-autoplot.R
> 
> set.seed(455)
> folds <- vfold_cv(mtcars, v = 5)
> 
> simple_rec <- recipe(mpg ~ ., data = mtcars)
> 
> form <- mpg ~ .
> 
> spline_rec <-
+   recipe(mpg ~ ., data = mtcars) %>%
+   step_normalize(all_predictors()) %>%
+   step_bs(disp, deg_free = tune())
> 
> lm_mod <- linear_reg() %>% set_engine("lm")
> 
> knn_mod <-
+   nearest_neighbor(mode = "regression", neighbors = tune()) %>%
+   set_engine("kknn")
> 
> knn_mod_two <-
+   nearest_neighbor(mode = "regression", neighbors = tune("K"), weight_func = tune()) %>%
+   set_engine("kknn")
> 
> get_coefs  <- function(x) {
+   x %>%
+     extract_fit_parsnip() %>%
+     tidy()
+ }
> 
> verb <- FALSE
> g_ctrl <- control_grid(verbose = verb, save_pred = TRUE, extract = get_coefs)
> b_ctrl <- control_bayes(verbose = verb, save_pred = TRUE, extract = get_coefs)
> 
> # ------------------------------------------------------------------------------
> 
> mt_spln_lm <-
+   workflow() %>%
+   add_recipe(spline_rec) %>%
+   add_model(lm_mod)
> 
> mt_spln_knn <-
+   workflow() %>%
+   add_recipe(spline_rec) %>%
+   add_model(knn_mod)
> 
> mt_knn <-
+   workflow() %>%
+   add_recipe(simple_rec) %>%
+   add_model(knn_mod)
> 
> # ------------------------------------------------------------------------------
> 
> set.seed(8825)
> mt_spln_lm_grid <-
+   tune_grid(mt_spln_lm,
+             resamples = folds,
+             control = g_ctrl)
→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient="NA")
There were issues with some computations   A: x1                                                 → B | warning: some 'x' values beyond boundary knots may cause ill-conditioned bases
There were issues with some computations   A: x1There were issues with some computations   A: x1   B: x4There were issues with some computations   A: x2   B: x10There were issues with some computations   A: x2   B: x11There were issues with some computations   A: x2   B: x17There were issues with some computations   A: x2   B: x20
> 
> set.seed(8825)
> mt_spln_lm_bo <-
+   tune_bayes(
+     mt_spln_lm,
+     resamples = folds,
+     iter = 3,
+     control = b_ctrl
+   )
→ A | warning: some 'x' values beyond boundary knots may cause ill-conditioned bases
There were issues with some computations   A: x1There were issues with some computations   A: x5There were issues with some computations   A: x6There were issues with some computations   A: x11There were issues with some computations   A: x13There were issues with some computations   A: x14There were issues with some computations   A: x16There were issues with some computations   A: x16
> 
> # ------------------------------------------------------------------------------
> 
> set.seed(8825)
> mt_spln_knn_grid <-
+   tune_grid(
+     mt_spln_knn,
+     resamples = folds,
+     grid = grid_regular(extract_parameter_set_dials(mt_spln_knn)),
+     control = g_ctrl
+   )
→ A | error:   No tidy method for objects of class train.kknn
There were issues with some computations   A: x3                                                 → B | warning: some 'x' values beyond boundary knots may cause ill-conditioned bases
There were issues with some computations   A: x3There were issues with some computations   A: x7   B: x3There were issues with some computations   A: x12   B: x3There were issues with some computations   A: x15   B: x6
> 
> set.seed(8825)
> mt_spln_knn_bo <-
+   tune_bayes(mt_spln_knn,
+              resamples = folds,
+              iter = 3,
+              control = b_ctrl)
→ A | error:   No tidy method for objects of class train.kknn
There were issues with some computations   A: x1There were issues with some computations   A: x4                                                 → B | warning: some 'x' values beyond boundary knots may cause ill-conditioned bases
There were issues with some computations   A: x4There were issues with some computations   A: x8   B: x2There were issues with some computations   A: x14   B: x5There were issues with some computations   A: x20   B: x5There were issues with some computations   A: x25   B: x9There were issues with some computations   A: x26   B: x10There were issues with some computations   A: x30   B: x12There were issues with some computations   A: x31   B: x12There were issues with some computations   A: x36   B: x14There were issues with some computations   A: x37   B: x14There were issues with some computations   A: x40   B: x16
> 
> set.seed(8825)
> mt_spln_knn_bo_sep <-
+   tune_bayes(knn_mod_two,
+              spline_rec,
+              resamples = folds,
+              iter = 3,
+              control = b_ctrl)
→ A | error:   No tidy method for objects of class train.kknn
There were issues with some computations   A: x1There were issues with some computations   A: x6                                                 → B | warning: some 'x' values beyond boundary knots may cause ill-conditioned bases
There were issues with some computations   A: x6There were issues with some computations   A: x12   B: x5There were issues with some computations   A: x18   B: x5There were issues with some computations   A: x24   B: x8! The Gaussian process model is being fit using 12 features but only has 5
  data points to do so. This may cause errors or a poor model fit.
                                                          → C | warning: did not converge in 10 iterations
There were issues with some computations   A: x24   B: x8There were issues with some computations   A: x25   B: x10   C: x1There were issues with some computations   A: x27   B: x10   C: x1! The Gaussian process model is being fit using 12 features but only has 6
  data points to do so. This may cause errors or a poor model fit.
There were issues with some computations   A: x31   B: x12   C: x1There were issues with some computations   A: x32   B: x13   C: x1! The Gaussian process model is being fit using 12 features but only has 7
  data points to do so. This may cause errors or a poor model fit.
There were issues with some computations   A: x36   B: x14   C: x1There were issues with some computations   A: x40   B: x16   C: x1
> 
> # ------------------------------------------------------------------------------
> 
> set.seed(8825)
> mt_knn_grid <- tune_grid(mt_knn, resamples = folds, control = g_ctrl)
→ A | error:   No tidy method for objects of class train.kknn
There were issues with some computations   A: x5There were issues with some computations   A: x5
> 
> set.seed(8825)
> mt_knn_bo <-
+   tune_bayes(mt_knn,
+              resamples = folds,
+              iter = 3,
+              control = b_ctrl)
→ A | error:   No tidy method for objects of class train.kknn
There were issues with some computations   A: x5There were issues with some computations   A: x11There were issues with some computations   A: x16There were issues with some computations   A: x20
> 
> # ------------------------------------------------------------------------------
> 
> save(
+   list = grep("^mt_", ls(), value = TRUE),
+   file = test_path("data", "test_objects.RData"),
+   version = 2,
+   compress = "xz"
+ )
> 
> # ------------------------------------------------------------------------------
> # "knn_*" test objects used in test-predictions.R, test-autoplot.R, test-GP.R
> # and test-select_best.R
> 
> data(two_class_dat, package = "modeldata")
> set.seed(7898)
> data_folds <- vfold_cv(two_class_dat, repeats = 5)
> 
> two_class_rec <-
+   recipe(Class ~ ., data = two_class_dat) %>%
+   step_normalize(A, B)
> 
> knn_model <-
+   nearest_neighbor(
+     mode = "classification",
+     neighbors = tune("K"),
+     weight_func = tune(),
+     dist_power = tune("exponent")
+   ) %>%
+   set_engine("kknn")
> 
> two_class_wflow <-
+   workflow() %>%
+   add_recipe(two_class_rec) %>%
+   add_model(knn_model)
> 
> two_class_set <-
+   extract_parameter_set_dials(two_class_wflow) %>%
+   update(K = neighbors(c(1, 50))) %>%
+   update(exponent = dist_power(c(1 / 10, 2)))
> 
> set.seed(2494)
> two_class_grid <-
+   two_class_set %>%
+   grid_max_entropy(size = 10)
> 
> class_metrics <- metric_set(roc_auc, accuracy, kap, mcc)
> 
> knn_results <-
+   tune_grid(
+     two_class_wflow,
+     resamples = data_folds,
+     grid = two_class_grid,
+     metrics = class_metrics
+   )
> 
> 
> knn_set <- two_class_set
> 
> knn_gp <-
+   tune:::fit_gp(collect_metrics(knn_results),
+                 knn_set,
+                 "accuracy",
+                 control_bayes()
+   )
Error in `dplyr::filter()`:
ℹ In argument: `.eval_time == eval_time`.
Caused by error:
! object '.eval_time' not found
Backtrace:
     ▆
  1. ├─tune:::fit_gp(...)
  2. │ └─dat %>% dplyr::filter(.eval_time == eval_time) at tune/R/tune_bayes.R:589:5
  3. ├─dplyr::filter(., .eval_time == eval_time)
  4. ├─dplyr:::filter.data.frame(., .eval_time == eval_time)
  5. │ └─dplyr:::filter_rows(.data, dots, by)
  6. │   └─dplyr:::filter_eval(...)
  7. │     ├─base::withCallingHandlers(...)
  8. │     └─mask$eval_all_filter(dots, env_filter)
  9. │       └─dplyr (local) eval()
 10. └─base::.handleSimpleError(...)
 11.   └─dplyr (local) h(simpleError(msg, call))
 12.     └─rlang::abort(message, class = error_class, parent = parent, call = error_call)
Execution halted
